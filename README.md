<div align="center">

# **The Chunking Subnet** <!-- omit in toc -->
### Intelligent RAG for Intelligent Applications <!-- omit in toc -->

![hero](./assets/title.png)



[VectorChat](https://vectorchat.ai) ‚Ä¢ [Chunking.com](https://chunking.com) ‚Ä¢ [Toffee](https://medium.com/@vectorchat/introducing-toffee-a-new-era-in-conversational-ai-cfd09c6648ae)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) 



</div>

# Introduction

Welcome to the Chunking subnet, Subnet 40 on the Bittensor Protocol! This subnet is designed to advance the field of Retrieval-Augmented Generation (RAG) by incentivizing the development and service of sophisticated chunking solutions. Specifically, the subnet aims to create, host, and serve an intelligent chunking solution that maximizes intrachunk similarity and interchunk dissimilarity.

Explore our subnet pitch deck: [placeholder]

Our article on why this is a valuable problem to solve: [The Case for Intelligent Chunking](https://medium.com/@vectorchat/the-case-for-intelligent-chunking-3f903aa3a72c)

Learn more about our project at [vectorchat.ai](https://vectorchat.ai)

## Advancing the Cutting-Edge

### *From the onset, this subnet will feature the most intelligent chunking algorithm publicly available!*

*Explore our benchmarks, methodology, and interactive demo here: [placeholder]().*

At VectorChat, our mission is to create the most immersive conversational AI experience. Our upcoming platform, [Toffee](https://medium.com/@vectorchat/introducing-toffee-a-new-era-in-conversational-ai-cfd09c6648ae), therefore leverages RAG to offer users seemingly endless memory and domain-specific knowledge.

While developing Toffee, we quickly found that the existing chunking solutions were either extremely rudimentary or were too resource-intensive, making RAG at scale both cost-prohibitive and less effective. In response, our team was able to develop an algorithm that significantly outperforms the current industry leaders.

However, our goal is to keep pushing the boundaries. The field of intelligent chunking is still in its infancy, and as LLMs begin to use increasingly large and diverse datasets (e.g., audio, image, video), the importance of intelligent chunking will only grow. Learn more about why this is the case [here](https://medium.com/@vectorchat/the-case-for-intelligent-chunking-3f903aa3a72c).

Therefore, we designed this subnet to have a straightforward, transparent, and fair incentive mechanism to surpass our own achievements. Explore the [subnet architecture](#architecture) below to learn how responses are evaluated fairly.

We believe the best solutions are yet to come and we are excited to see how miners can push the boundaries of this technology! 


# Architecture
* üìù [Evaluation](./docs/evaluation.md)
* üí∞ [Incentive Mechanism](./docs/evaluation.md)
* üß™ [Synthetic Queries]()
* üå± [Organic Queries & the Task API(s)]()

# Ethos
### *Models always stay on your machine and remain under your full ownership!*

As mentioned in our pitch deck, chunking is an infinitely complex problem that can be approached from countless different avenues. Given sufficiently long, semantically meaningful text, there is no single correct answer, only "more" correct ones. Bittensor is an excellent way to tackle such a problem, as it incentivizes both innovation and fine-tuned optimization to find the most effective solution.

We **do not open-source** the models created, **nor do we ever receive them**. We believe this greatly increases the incentive for developing the best solution, as miners retain full ownership of their work, thereby enhancing the effectiveness of this subnet.

At the same time, we believe this increases the value brought to the Bittensor protocol, as access to the best chunking model will require a **constant sufficient stake**. Since validators never receive the model, but only the right to serve queries, losing stake in the network also results in losing access to any model produced by the subnet.

# Getting Started

## Helpful Resources
For those new to chunking or Retrieval Augmented Generation (RAG), we strongly recommend you check out our articles here:

* [What is Chunking?]()
* [The Case for Intelligent Chunking](https://medium.com/@vectorchat/the-case-for-intelligent-chunking-3f903aa3a72c)

We also recommend these resources by [Pinecone.io](https://www.pinecone.io/):
* [Retrieval-Augmented Generation](https://www.pinecone.io/learn/retrieval-augmented-generation/)
* [Chunking Strategies for LLM Applications](https://www.pinecone.io/learn/chunking-strategies/)
* [What is a Vector Database?](https://www.pinecone.io/learn/vector-database/)

## Installation

To learn how to set up a miner, see [Default Miner](./docs/default_miner.md). This is a very simple miner to get you started. We highly recommend you read our [Guide to Mining](./docs/miner_guide.md) to create your own logic.

For validator setup and considerations, please view [Validation](./docs/validation.md).

# Roadmap

Our goal is to establish this subnet as the premier source for the most advanced chunking solution, thereby achieving profitability in the near future.

**Phase 1:** 
- [ ] Release our opt-in Task API, enabling validators to receive and monetize organic queries.
- [ ] Release framework for validators to create their own Task API network.
- [ ] Launch subnet dashboards for miners and validators, displaying performance, statistics, and tracking compensation.

**Phase 2:**
- [ ] Launch of Chunking.com, our front-end service delivering cutting-edge RAG to developers and enterprises.
- [ ] Launch of Toffee, our conversational AI platform using RAG to create an unparalleled user experience.

**Phase 3:**
- [ ] Expand to include special queries and evaluations for structure-dependent data (e.g., CSV).
- [ ] Expand to include new data modalities requiring novel chunking solutions (e.g., image, audio, and video).
