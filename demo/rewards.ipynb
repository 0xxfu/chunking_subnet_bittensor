{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward mechanism demo\n",
    "\n",
    "## Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.protocol import chunkSynapse\n",
    "import bittensor as bt\n",
    "import requests\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netuid = 1 # TODO: set netuid\n",
    "network = 'ws://localhost:9946' # TODO: set network\n",
    "\n",
    "metagraph = bt.metagraph(netuid, network)\n",
    "\n",
    "metagraph.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_name = \"owner\" # TODO: set wallet name\n",
    "hotkey_name = \"validator-1\" # TODO: set hotkey name\n",
    "\n",
    "validator_wallet = bt.wallet(name=wallet_name, hotkey=hotkey_name)\n",
    "validator_dendrite = bt.dendrite(wallet=validator_wallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the top miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 33653136 # hard article id\n",
    "\n",
    "def generate_synthetic_synapse() -> chunkSynapse:    \n",
    "    document = requests.get('https://en.wikipedia.org/w/api.php', params={\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'pageids': page,\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': True,\n",
    "        'exsectionformat': 'plain',\n",
    "        }).json()['query']['pages'][str(page)]['extract']\n",
    "    document = document.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    document = ' '.join(document.split())\n",
    "    synapse = chunkSynapse(document=document, time_soft_max=5.0, chunk_size=4096)\n",
    "    return synapse\n",
    "\n",
    "\n",
    "top_miner_uid = metagraph.I.argmax().item()\n",
    "\n",
    "top_miner_axon = metagraph.axons[top_miner_uid]\n",
    "\n",
    "# Generate the 'synthetic' query: a featured article from wikipedia.\n",
    "synapse = generate_synthetic_synapse()\n",
    "\n",
    "top_miner_response = validator_dendrite.query(\n",
    "    axons=[top_miner_axon],    \n",
    "    synapse=synapse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward the top miners response\n",
    "\n",
    "### Reward Mechanism\n",
    "\n",
    "1) Chunks must not have missing words/messed up ordering\n",
    "    - every continguous three word pair from the source document should be in at least 1 chunk\n",
    "    - every word in a single chunk should be in the same order as in the source document\n",
    "2) There is a penalty for chunks that are too long (> `chunk_size` characters)\n",
    "    - Snippet:\n",
    "     ```py\n",
    "     size_penalty += ((chunk_length / chunk_size) - 1) * 10\n",
    "     ```\n",
    "3) Intra-chunk embeddings should have high cosine similarity, inter-chunk embeddings should have low cosine similarity\n",
    "    \n",
    "    - Snippet:\n",
    "    ```py\n",
    "    for i in range(len(testChunks) - 1):\n",
    "        j = i + 1\n",
    "        while j < len(testChunks):\n",
    "            if testChunks[i].sourceChunk == testChunks[j].sourceChunk:\n",
    "                reward += np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j]))\n",
    "            else:\n",
    "                reward -= np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j]))\n",
    "            j += 1\n",
    "    ```\n",
    "\n",
    "    - `testChunks` are three sentence chunks formed from each of the returned miner chunks\n",
    "    - `embeddings` are the embeddings of the three sentence chunks, via OpenAI's `text-embedding-ada-002` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from chunking.validator.reward import reward\n",
    "import os\n",
    "\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise Exception(\"Make sure to set the OPENAI_API_KEY environment variable. `export OPENAI_API_KEY=your-key`\")\n",
    "\n",
    "\n",
    "top_miner_reward = reward(None, synapse.document, synapse.chunk_size, synapse, OpenAI(), override_num_embeddings=50)\n",
    "\n",
    "top_miner_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
