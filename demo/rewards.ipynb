{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward mechanism demo\n",
    "\n",
    "## Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.protocol import chunkSynapse\n",
    "import bittensor as bt\n",
    "import requests\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv tabulate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API key necessary for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise Exception(\"Make sure to set OPENAI_API_KEY in your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12974747, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.51534295, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.06547646, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25828946, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03109789,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netuid = 40\n",
    "network = \"ws://subvortex.info:9944\" # or 'finney'\n",
    "\n",
    "metagraph = bt.metagraph(netuid, network)\n",
    "\n",
    "metagraph.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wallet setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_name = \"owner\" # TODO: set wallet name\n",
    "hotkey_name = \"validator-1\" # TODO: set hotkey name\n",
    "\n",
    "validator_wallet = bt.wallet(name=wallet_name, hotkey=hotkey_name)\n",
    "validator_dendrite = bt.dendrite(wallet=validator_wallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the top miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import chunking\n",
    "\n",
    "importlib.reload(chunking)\n",
    "\n",
    "import chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking.validator.task_api import generate_synthetic_synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top miner uid: 18\n",
      "Document: ? (also written Tanda Tanya, meaning Question Mark) is a 2011 Indonesian drama film directed by Hanu ...\n",
      "Received 5 chunks from top miner, process time: 0.835676908493042\n",
      "Chunk 3: The director of Mahaka Pictures, Erick Thohir, sta ...\n"
     ]
    }
   ],
   "source": [
    "page = 33653136 # fixed article id\n",
    "\n",
    "top_miner_uid = metagraph.I.argmax().item()\n",
    "\n",
    "print(f\"Top miner uid: {top_miner_uid}\")\n",
    "\n",
    "top_miner_axon = metagraph.axons[top_miner_uid]\n",
    "\n",
    "# Generate the 'synthetic' query: a featured article from wikipedia.\n",
    "synapse, pageid = generate_synthetic_synapse(None, pageid=page, timeout=20)\n",
    "\n",
    "\n",
    "print(f\"Document: {synapse.document[:100]} ...\")\n",
    "\n",
    "responses: list[chunkSynapse] = validator_dendrite.query(\n",
    "    axons=[top_miner_axon],    \n",
    "    synapse=synapse,\n",
    "    deserialize=False\n",
    ")\n",
    "\n",
    "top_miner_response = responses[0]\n",
    "\n",
    "print(f\"Received {len(top_miner_response.chunks)} chunks from top miner, process time: {top_miner_response.dendrite.process_time}\")\n",
    "print(f\"Chunk 3: {top_miner_response.chunks[2][:50]} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward the top miners response\n",
    "\n",
    "### Reward Mechanism\n",
    "\n",
    "1) Chunks must not have missing words/messed up ordering\n",
    "    - every continguous three word pair from the source document should be in at least 1 chunk\n",
    "    - every word in a single chunk should be in the same order as in the source document\n",
    "2) There is a penalty for chunks that are too long (> `chunk_size` characters)\n",
    "    - Snippet:\n",
    "     ```py\n",
    "     size_penalty += ((chunk_length / chunk_size) - 1) * 10\n",
    "     ```\n",
    "3) Intra-chunk embeddings should have high cosine similarity, inter-chunk embeddings should have low cosine similarity\n",
    "    \n",
    "    - Snippet:\n",
    "    ```py\n",
    "    for i in range(len(testChunks) - 1):\n",
    "        j = i + 1\n",
    "        while j < len(testChunks):\n",
    "            if testChunks[i].sourceChunk == testChunks[j].sourceChunk:\n",
    "                reward += np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j]))\n",
    "            else:\n",
    "                reward -= np.dot(np.asarray(embeddings[i]), np.asarray(embeddings[j]))\n",
    "            j += 1\n",
    "    ```\n",
    "\n",
    "    - `testChunks` are three sentence chunks formed from each of the returned miner chunks\n",
    "    - `embeddings` are the embeddings of the three sentence chunks, via OpenAI's `text-embedding-ada-002` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_extra_info_dict(extra_info_dicts: list[dict], uids: list[int]):\n",
    "    assert len(extra_info_dicts) == len(uids)\n",
    "    \n",
    "    table_data = []\n",
    "    \n",
    "    for extra_info_dict, uid in zip(extra_info_dicts, uids):\n",
    "        table_data.append([\n",
    "            uid,\n",
    "            extra_info_dict.get(\"embedding_reward\", 0),             \n",
    "            extra_info_dict.get(\"size_penalty\", 0),\n",
    "            extra_info_dict.get(\"qty_penalty\", 0)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    table_str = tabulate(table_data, headers=[\"UID\", \"Embedding reward\", \"Size penalty\", \"Quantity penalty\"], tablefmt=\"grid\")\n",
    "    \n",
    "    print(table_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.01349250084228093\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135839353959122\n",
      "  UID    Embedding reward    Size penalty    Quantity penalty\n",
      "-----  ------------------  --------------  ------------------\n",
      "   18           0.0134925               0                   0\n",
      "Top miner reward: 1.0135839353959122\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from chunking.validator.reward import reward\n",
    "\n",
    "bt.debug()\n",
    "\n",
    "print(synapse.chunk_qty)\n",
    "\n",
    "top_miner_reward, extra_info_dict = reward(self=None, document=synapse.document, chunk_size=synapse.chunk_size, chunk_qty=synapse.chunk_qty, response=top_miner_response, override_client=OpenAI(), override_num_embeddings=50, verbose=True)\n",
    "\n",
    "print_extra_info_dict([extra_info_dict], [top_miner_uid])\n",
    "\n",
    "print(f\"Top miner reward: {top_miner_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group tournament ranking\n",
    "\n",
    "Generally, a miner group is queried by a validator at request time. The default group size is `min(metagraph.n, 25)`. The validator will then rank the miners in this group relative to each other based on the incentive mechanism. These local ranks will be then translated into global ranks. Having a lower overall rank is better.\n",
    "\n",
    "Here's an example of querying a group of 4 miners (assuming the `group_size` is 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 miners uids: [ 18 116  13 100]\n",
      "Received 5 chunks from hotkey: 5F2LKK2qEt, process time: 0.7323508262634277\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.013467973409598932\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135590750890504\n",
      "Received 5 chunks from hotkey: 5G7HVdSrYj, process time: 0.819551944732666\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.013493854649931691\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135853075945276\n",
      "Received 0 chunks from hotkey: 5CdQ2JNXao, process time: No process time found\n",
      "Received 5 chunks from hotkey: 5GFC2SpRcL, process time: 0.8030498027801514\n",
      "Chunk 0 has 33 sentences. Added 11 test segments\n",
      "Chunk 1 has 41 sentences. Added 14 test segments\n",
      "Chunk 2 has 33 sentences. Added 11 test segments\n",
      "Chunk 3 has 33 sentences. Added 11 test segments\n",
      "Chunk 4 has 8 sentences. Added 3 test segments\n",
      "Every set of 3 adjacent words from the document appears in the chunks\n",
      "Using 50 test segments for evaluation\n",
      "Calculated embeddings for 50 test segments\n",
      "Embedding reward: 0.01348732129546315\n",
      "Size penalty: 0\n",
      "Quantity penalty: 0\n",
      "Ensuring reward is positive (e ** reward):\n",
      "1.0135786855040612\n",
      "Rewards: [1.01355908 1.01358531 0.         1.01357869]\n",
      "Response ranks: [ 2.  0. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from chunking.validator.reward import rank_responses\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "top_4_miners_uids = metagraph.I.argsort()[-4:][::-1]\n",
    "\n",
    "print(f\"Top 4 miners uids: {top_4_miners_uids}\")\n",
    "\n",
    "axons = [metagraph.axons[uid] for uid in top_4_miners_uids]\n",
    "\n",
    "responses: list[chunkSynapse] = validator_dendrite.query(\n",
    "    axons=axons,\n",
    "    synapse=synapse,\n",
    "    deserialize=False\n",
    ")\n",
    "\n",
    "rewards = []\n",
    "extra_info_dicts = []\n",
    "\n",
    "for response in responses:\n",
    "    num_chunks = len(response.chunks) if response.chunks else 0\n",
    "    hotkey_str = response.axon.hotkey[:10] if response.axon.hotkey else \"No hotkey found\"\n",
    "    process_time = response.dendrite.process_time if response.dendrite.process_time else \"No process time found\"\n",
    "    \n",
    "    print(f\"Received {num_chunks} chunks from hotkey: {hotkey_str}, process time: {process_time}\")    \n",
    "\n",
    "    if not response.chunks:\n",
    "        rewards.append(0)\n",
    "        extra_info_dicts.append({})\n",
    "        continue\n",
    "    reward_value, extra_info_dict = reward(self=None, document=synapse.document, chunk_size=synapse.chunk_size, chunk_qty=synapse.chunk_qty, response=response, override_client=OpenAI(), override_num_embeddings=50, verbose=True)    \n",
    "    rewards.append(reward_value)\n",
    "    extra_info_dicts.append(extra_info_dict)\n",
    "\n",
    "rewards = np.array(rewards)\n",
    "\n",
    "print(f\"Rewards: {rewards}\")\n",
    "\n",
    "response_ranks = rank_responses(rewards)\n",
    "\n",
    "print(f\"Response ranks: {response_ranks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+\n",
      "|   UID |   Embedding reward |   Size penalty |   Quantity penalty |\n",
      "+=======+====================+================+====================+\n",
      "|    18 |          0.013468  |              0 |                  0 |\n",
      "+-------+--------------------+----------------+--------------------+\n",
      "|   116 |          0.0134939 |              0 |                  0 |\n",
      "+-------+--------------------+----------------+--------------------+\n",
      "|    13 |          0         |              0 |                  0 |\n",
      "+-------+--------------------+----------------+--------------------+\n",
      "|   100 |          0.0134873 |              0 |                  0 |\n",
      "+-------+--------------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print_extra_info_dict(extra_info_dicts, top_4_miners_uids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These response ranks would then be translated into global ranks (no change in this case as they are the top 4 miners) and combined with the previous `scores` as a moving average (therefore a lower `score` is better, even if a higher `reward` is better). \n",
    "\n",
    "- Weights are then determined based on the global `scores` (which is basically just ranks as a moving average for all miner UIDs)\n",
    "\n",
    "- So, if the ranks are [2, 0, 3, 1] (0-indexed), the scores might be something like [2.0393, .4593, 2.539, 1.3940] (as it is the moving average of ranks), and the weights would be [0.5, 1, 0.25, 0.75], where each index is a UID."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
